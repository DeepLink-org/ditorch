{
  "test_affine_grid_3d (__main__.TestNN)": [
    "",
    [
      "linux"
    ]
  ],
  "test_AdaptiveLogSoftmax_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_BCELoss_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-13-06:07:07.855.407 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_BCELoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-13-06:07:07.886.483 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_BCELoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-13-06:07:07.912.399 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_BCELoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-13-06:07:07.923.246 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_BCELoss_scalar_weights_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-13-06:07:08.440.197 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_BCELoss_weights_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-13-06:07:08.843.996 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_BCELoss_weights_no_reduce_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_BCEWithLogitsLoss_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnBinaryCrossEntropyWithLogits failed, detail:EZ1001: 2024-09-13-06:07:09.938.131 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_BCEWithLogitsLoss_cuda_half (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_BCEWithLogitsLoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnBinaryCrossEntropyWithLogits failed, detail:EZ1001: 2024-09-13-06:07:13.352.126 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_BCEWithLogitsLoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnBinaryCrossEntropyWithLogits failed, detail:EZ1001: 2024-09-13-06:07:13.369.092 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_BCEWithLogitsLoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnBinaryCrossEntropyWithLogits failed, detail:EZ1001: 2024-09-13-06:07:13.377.808 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_BCEWithLogitsLoss_scalar_weights_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnBinaryCrossEntropyWithLogits failed, detail:EZ1001: 2024-09-13-06:07:14.256.826 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_BCEWithLogitsLoss_scalar_weights_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_BCEWithLogitsLoss_scalar_weights_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_BCEWithLogitsLoss_weights_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnBinaryCrossEntropyWithLogits failed, detail:EZ1001: 2024-09-13-06:07:15.237.542 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_2d_int_target_lengths_intlists_cuda_double (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_2d_int_target_lengths_intlists_cuda_float (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_2d_int_target_lengths_intlists_sum_reduction_cuda_double (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_2d_int_target_lengths_intlists_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_2d_int_target_lengths_tensors_cuda_double (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_2d_int_target_lengths_tensors_cuda_float (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_2d_int_target_lengths_tensors_sum_reduction_cuda_double (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_2d_int_target_lengths_tensors_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_2d_lengths_tensors_cuda_double (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_2d_lengths_tensors_cuda_float (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_2d_lengths_tensors_sum_reduction_cuda_double (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_critical_target_len (__main__.TestNN)": [
    "RuntimeError: only npu tensor is supported",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_lengths_intlists_cuda_double (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_lengths_intlists_cuda_float (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_lengths_intlists_sum_reduction_cuda_double (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_lengths_intlists_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_lengths_tensors_cuda_double (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_lengths_tensors_cuda_float (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_lengths_tensors_sum_reduction_cuda_double (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_lengths_tensors_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv1d_circular_stride2_pad2_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv1d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv1d_dilated_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv1d_groups_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv1d_pad1_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv1d_pad1size1_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv1d_pad2_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv1d_pad2size1_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv1d_pad_same2_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv1d_pad_same_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv1d_pad_same_dilated_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv1d_pad_valid_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv1d_reflect_stride2_pad2_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv1d_replicate_stride2_pad2_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv1d_stride_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv1d_zeros_stride2_pad2_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv2d_circular_stride2_pad2_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv2d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv2d_depthwise_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv2d_depthwise_dilated_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv2d_depthwise_padded_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv2d_depthwise_strided_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv2d_depthwise_with_multiplier_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv2d_dilated_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv2d_groups_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv2d_groups_thnn_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv2d_no_bias_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv2d_pad_same_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv2d_pad_same_dilated_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv2d_pad_valid_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv2d_padding_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv2d_reflect_stride2_pad2_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv2d_replicate_stride2_pad2_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv2d_strided_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv2d_zeros_stride2_pad2_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv3d (__main__.TestNN)": [
    "RuntimeError: The Inner error is reported as above.",
    [
      "linux"
    ]
  ],
  "test_Conv3d_1x1x1_no_bias_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv3d_circular_stride2_pad2_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv3d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv3d_dilated_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv3d_dilated_strided_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv3d_groups_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv3d_no_bias_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv3d_pad_same_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv3d_pad_same_dilated_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv3d_pad_valid_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv3d_replicate_stride2_pad2_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv3d_stride_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv3d_stride_padding_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv3d_zero_batch_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Conv3d_zeros_stride2_pad2_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_ConvTranspose1d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_ConvTranspose1d_dilated_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_ConvTranspose1d_groups_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_ConvTranspose1d_no_bias_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_ConvTranspose2d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_ConvTranspose2d_dilated_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_ConvTranspose2d_groups_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_ConvTranspose2d_no_bias_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_ConvTranspose3d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_ConvTranspose3d_dilated_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_CosineEmbeddingLoss_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CosineEmbeddingLoss_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CosineEmbeddingLoss_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CosineEmbeddingLoss_margin_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CosineEmbeddingLoss_margin_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CosineEmbeddingLoss_margin_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CosineEmbeddingLoss_margin_sum_reduction_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CosineEmbeddingLoss_margin_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CosineEmbeddingLoss_margin_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CosineEmbeddingLoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CosineEmbeddingLoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CosineEmbeddingLoss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CosineEmbeddingLoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CosineEmbeddingLoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CosineEmbeddingLoss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CosineEmbeddingLoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CosineEmbeddingLoss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CosineEmbeddingLoss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CosineEmbeddingLoss_sum_reduction_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CosineEmbeddingLoss_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CosineEmbeddingLoss_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-06:07:39.180.732 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_ignore_index_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-06:07:39.198.070 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_ignore_index_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_ignore_index_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_indices_target_smoothing_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:07:39.214.852 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_indices_target_smoothing_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_indices_target_smoothing_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_indices_target_smoothing_ignore_index_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:07:39.235.160 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_indices_target_smoothing_ignore_index_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_indices_target_smoothing_ignore_index_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_indices_target_smoothing_sum_reduction_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:07:39.253.220 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_indices_target_smoothing_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_indices_target_smoothing_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_indices_target_smoothing_weight_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:07:39.271.164 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_indices_target_smoothing_weight_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_indices_target_smoothing_weight_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_prob_target_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_prob_target_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_prob_target_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_prob_target_smoothing_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_prob_target_smoothing_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_prob_target_smoothing_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_prob_target_smoothing_sum_reduction_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_prob_target_smoothing_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_prob_target_smoothing_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_prob_target_smoothing_weight_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_prob_target_smoothing_weight_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_prob_target_smoothing_weight_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_prob_target_sum_reduction_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_prob_target_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_prob_target_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_prob_target_weights_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_prob_target_weights_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_prob_target_weights_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_prob_target_weights_sum_reduction_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_prob_target_weights_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_prob_target_weights_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_sum_reduction_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-06:07:39.330.185 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_weights_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-06:07:39.345.119 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_weights_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_2d_weights_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_indices_target_smoothing_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-06:07:39.362.027 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_indices_target_smoothing_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_indices_target_smoothing_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_indices_target_smoothing_ignore_index_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-06:07:39.381.061 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_indices_target_smoothing_ignore_index_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_indices_target_smoothing_ignore_index_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_indices_target_smoothing_sum_reduction_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-06:07:39.399.988 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_indices_target_smoothing_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_indices_target_smoothing_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_indices_target_smoothing_sum_reduction_ignore_index_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-06:07:39.418.639 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_indices_target_smoothing_sum_reduction_ignore_index_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_indices_target_smoothing_sum_reduction_ignore_index_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_prob_target_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_prob_target_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_prob_target_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_prob_target_smoothing_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_prob_target_smoothing_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_prob_target_smoothing_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_prob_target_smoothing_sum_reduction_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_prob_target_smoothing_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_prob_target_smoothing_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_prob_target_sum_reduction_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_prob_target_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_prob_target_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_prob_target_weights_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_prob_target_weights_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_prob_target_weights_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_prob_target_weights_sum_reduction_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_prob_target_weights_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_3d_prob_target_weights_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_4d_prob_target_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_4d_prob_target_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_4d_prob_target_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_4d_prob_target_sum_reduction_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_4d_prob_target_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_4d_prob_target_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_4d_prob_target_weights_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_4d_prob_target_weights_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_4d_prob_target_weights_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_4d_prob_target_weights_sum_reduction_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_4d_prob_target_weights_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_4d_prob_target_weights_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:07:39.499.931 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_dim_is_3_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-06:07:39.516.894 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_dim_is_3_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_dim_is_3_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_dim_is_3_sum_reduction_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-06:07:39.533.271 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_dim_is_3_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_dim_is_3_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_higher_dim_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-06:07:39.550.958 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_higher_dim_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_higher_dim_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_higher_dim_sum_reduction_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-06:07:39.567.900 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_higher_dim_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_higher_dim_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_weights_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:07:39.584.418 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_weights_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossEntropyLoss_weights_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_CrossMapLRN2d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_ELU_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_EmbeddingBag_discontiguous_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_EmbeddingBag_max_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_EmbeddingBag_max_padding_idx_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_EmbeddingBag_mean_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_EmbeddingBag_mean_padding_idx_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_EmbeddingBag_sparse_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_EmbeddingBag_sum_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_EmbeddingBag_sum_padding_idx_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Embedding_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Embedding_discontiguous_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Embedding_sparse_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Flatten_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Flatten_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Fold_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Fold_int_input_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Fold_no_batch_dim_input_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Fold_no_batch_dim_int_input_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_GELU_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_GLU_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Hardshrink_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Hardsigmoid_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Hardswish_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Hardtanh_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_margin_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_margin_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_margin_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_margin_no_reduce_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_margin_sum_reduction_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_margin_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_margin_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_no_reduce_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_scalar_margin_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_scalar_margin_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_scalar_margin_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_scalar_margin_sum_reduction_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_scalar_margin_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_scalar_margin_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_sum_reduction_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HingeEmbeddingLoss_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_HuberLoss_delta (__main__.TestNN)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_HuberLoss_delta_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-06:07:40.146.191 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_log_target_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-06:07:41.037.862 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_log_target_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_log_target_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_log_target_sum_reduction_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-06:07:42.337.748 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_log_target_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_log_target_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-06:07:42.841.916 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-06:07:42.851.307 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-06:07:42.859.800 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_no_reduce (__main__.TestNN)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_no_reduce_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_no_reduce_log_target (__main__.TestNN)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_no_reduce_log_target_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_no_reduce_scalar (__main__.TestNN)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_no_reduce_scalar_cuda (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_no_reduce_scalar_log_target (__main__.TestNN)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_no_reduce_scalar_log_target_cuda (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_scalar_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-06:07:43.838.438 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_scalar_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_scalar_log_target_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-06:07:43.848.335 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_scalar_log_target_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_scalar_log_target_sum_reduction_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-06:07:43.856.804 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_scalar_log_target_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_scalar_sum_reduction_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-06:07:43.864.679 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_scalar_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_sum_reduction_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-06:07:44.137.783 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_with_log_target_no_reduce (__main__.TestNN)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_with_log_target_no_reduce_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_with_target_no_reduce (__main__.TestNN)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_KLDivLoss_with_target_no_reduce_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_L1Loss_cuda_cdouble (__main__.TestNN)": [
    "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-06:07:45.151.000 Input dtype should be either floating point or complex dtypes. Got self DT_COMPLEX128 and target DT_COMPLEX128 instead.",
    [
      "linux"
    ]
  ],
  "test_L1Loss_cuda_cfloat (__main__.TestNN)": [
    "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-06:07:45.155.455 Input dtype should be either floating point or complex dtypes. Got self DT_COMPLEX64 and target DT_COMPLEX64 instead.",
    [
      "linux"
    ]
  ],
  "test_L1Loss_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-06:07:45.159.071 promoteType dtype DT_DOUBLE should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_L1Loss_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_L1Loss_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_L1Loss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-06:07:45.168.012 promoteType dtype DT_DOUBLE should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_L1Loss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_L1Loss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_L1Loss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-06:07:45.177.156 promoteType dtype DT_DOUBLE should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_L1Loss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_L1Loss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_L1Loss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-06:07:45.184.518 promoteType dtype DT_DOUBLE should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_L1Loss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_L1Loss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_L1Loss_no_reduce (__main__.TestNN)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_L1Loss_no_reduce_complex (__main__.TestNN)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_L1Loss_no_reduce_complex_cuda (__main__.TestNN)": [
    "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-06:07:45.197.667 promoteType dtype DT_COMPLEX128 should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_L1Loss_no_reduce_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_L1Loss_no_reduce_scalar (__main__.TestNN)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_L1Loss_no_reduce_scalar_cuda (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_L1Loss_scalar_cuda_cdouble (__main__.TestNN)": [
    "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-06:07:45.209.090 Input dtype should be either floating point or complex dtypes. Got self DT_COMPLEX128 and target DT_COMPLEX128 instead.",
    [
      "linux"
    ]
  ],
  "test_L1Loss_scalar_cuda_cfloat (__main__.TestNN)": [
    "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-06:07:45.213.146 Input dtype should be either floating point or complex dtypes. Got self DT_COMPLEX64 and target DT_COMPLEX64 instead.",
    [
      "linux"
    ]
  ],
  "test_L1Loss_scalar_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-06:07:45.217.005 promoteType dtype DT_DOUBLE should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_L1Loss_scalar_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_L1Loss_scalar_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_LayerNorm_3d_no_affine_large_feature_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_LayerNorm_3d_no_affine_large_feature_eval_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_LeakyReLU_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Linear_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Linear_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Linear_no_bias_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_LogSigmoid_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_MSELoss_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-13-06:07:45.750.281 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.",
    [
      "linux"
    ]
  ],
  "test_MSELoss_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MSELoss_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MSELoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-13-06:07:45.760.949 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.",
    [
      "linux"
    ]
  ],
  "test_MSELoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MSELoss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MSELoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-13-06:07:45.770.753 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.",
    [
      "linux"
    ]
  ],
  "test_MSELoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MSELoss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MSELoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-13-06:07:45.779.431 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.",
    [
      "linux"
    ]
  ],
  "test_MSELoss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MSELoss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MSELoss_no_reduce (__main__.TestNN)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_MSELoss_no_reduce_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_MSELoss_no_reduce_scalar (__main__.TestNN)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_MSELoss_no_reduce_scalar_cuda (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MSELoss_prec_cuda_bfloat16 (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_MSELoss_prec_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-13-06:07:45.846.510 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.",
    [
      "linux"
    ]
  ],
  "test_MSELoss_prec_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MSELoss_prec_cuda_half (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_MSELoss_scalar_cuda_bfloat16 (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MSELoss_scalar_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-13-06:07:45.893.719 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.",
    [
      "linux"
    ]
  ],
  "test_MSELoss_scalar_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MSELoss_scalar_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MSELoss_scalar_sum_reduction_cuda_bfloat16 (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MSELoss_scalar_sum_reduction_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-13-06:07:45.905.938 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.",
    [
      "linux"
    ]
  ],
  "test_MSELoss_scalar_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MSELoss_scalar_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MSELoss_sum_reduction_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnMseLoss failed, detail:EZ1001: 2024-09-13-06:07:45.916.538 Expected self dtype [DT_DOUBLE] and target dtype [DT_DOUBLE] to be promotable but check failed.",
    [
      "linux"
    ]
  ],
  "test_MSELoss_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MSELoss_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MarginRankingLoss_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MarginRankingLoss_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MarginRankingLoss_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MarginRankingLoss_margin_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MarginRankingLoss_margin_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MarginRankingLoss_margin_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MarginRankingLoss_margin_sum_reduction_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MarginRankingLoss_margin_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MarginRankingLoss_margin_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MarginRankingLoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MarginRankingLoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MarginRankingLoss_sum_reduction_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MarginRankingLoss_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MarginRankingLoss_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MaxUnpool1d_net (__main__.TestNN)": [
    "RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-13-06:07:45.988.109 indices expected scalar type DT_INT64 but found DT_INT8.",
    [
      "linux"
    ]
  ],
  "test_MaxUnpool1d_net_cuda (__main__.TestNN)": [
    "RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-13-06:07:45.994.286 indices expected scalar type DT_INT64 but found DT_INT8.",
    [
      "linux"
    ]
  ],
  "test_MaxUnpool1d_net_no_batch_dim (__main__.TestNN)": [
    "RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-13-06:07:46.004.892 indices expected scalar type DT_INT64 but found DT_INT8.",
    [
      "linux"
    ]
  ],
  "test_MaxUnpool1d_net_no_batch_dim_cuda (__main__.TestNN)": [
    "RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-13-06:07:46.010.192 indices expected scalar type DT_INT64 but found DT_INT8.",
    [
      "linux"
    ]
  ],
  "test_MaxUnpool2d_net (__main__.TestNN)": [
    "RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-13-06:07:46.019.421 indices expected scalar type DT_INT64 but found DT_INT8.",
    [
      "linux"
    ]
  ],
  "test_MaxUnpool2d_net_cuda (__main__.TestNN)": [
    "RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-13-06:07:46.025.141 indices expected scalar type DT_INT64 but found DT_INT8.",
    [
      "linux"
    ]
  ],
  "test_MaxUnpool2d_net_no_batch_dim (__main__.TestNN)": [
    "RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-13-06:07:46.035.690 indices expected scalar type DT_INT64 but found DT_INT8.",
    [
      "linux"
    ]
  ],
  "test_MaxUnpool2d_net_no_batch_dim_cuda (__main__.TestNN)": [
    "RuntimeError: call aclnnMaxUnpool2d failed, detail:EZ1001: 2024-09-13-06:07:46.041.649 indices expected scalar type DT_INT64 but found DT_INT8.",
    [
      "linux"
    ]
  ],
  "test_MaxUnpool3d_net_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_MaxUnpool3d_net_no_batch_dim (__main__.TestNN)": [
    "RuntimeError: call aclnnMaxUnpool3d failed, detail:EZ1001: 2024-09-13-06:07:46.056.926 indices expected scalar type DT_INT64 but found DT_FLOAT.",
    [
      "linux"
    ]
  ],
  "test_MaxUnpool3d_net_no_batch_dim_cuda (__main__.TestNN)": [
    "RuntimeError: call aclnnMaxUnpool3d failed, detail:EZ1001: 2024-09-13-06:07:46.062.370 indices expected scalar type DT_INT64 but found DT_FLOAT.",
    [
      "linux"
    ]
  ],
  "test_Mish_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_1d_cuda_bfloat16 (__main__.TestNN)": [
    "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:46.096.884 self not implemented for DT_BFLOAT16, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_1d_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:46.102.799 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_1d_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_1d_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_1d_no_reduce_cuda (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_1d_sum_reduction_cuda_bfloat16 (__main__.TestNN)": [
    "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:46.119.351 self not implemented for DT_BFLOAT16, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_1d_sum_reduction_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:46.125.356 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_1d_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_1d_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_cuda_bfloat16 (__main__.TestNN)": [
    "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:46.133.701 self not implemented for DT_BFLOAT16, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:46.139.577 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_index_neg_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:46.153.299 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:46.162.463 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:46.171.191 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_no_reduce_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_sum_reduction_cuda_bfloat16 (__main__.TestNN)": [
    "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:46.198.007 self not implemented for DT_BFLOAT16, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_sum_reduction_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnMultilabelMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:46.204.205 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelMarginLoss_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelSoftMarginLoss_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-13-06:07:46.213.781 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_MultiLabelSoftMarginLoss_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelSoftMarginLoss_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelSoftMarginLoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-13-06:07:46.224.916 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_MultiLabelSoftMarginLoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelSoftMarginLoss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelSoftMarginLoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-13-06:07:46.236.258 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_MultiLabelSoftMarginLoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelSoftMarginLoss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelSoftMarginLoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-13-06:07:46.247.902 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_MultiLabelSoftMarginLoss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelSoftMarginLoss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelSoftMarginLoss_no_reduce_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelSoftMarginLoss_weights_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-13-06:07:46.263.068 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_MultiLabelSoftMarginLoss_weights_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelSoftMarginLoss_weights_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelSoftMarginLoss_weights_no_reduce_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelSoftMarginLoss_weights_sum_reduction_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-13-06:07:46.278.440 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_MultiLabelSoftMarginLoss_weights_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiLabelSoftMarginLoss_weights_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiMarginLoss_1d_cuda_half (__main__.TestNN)": [
    "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
    [
      "linux"
    ]
  ],
  "test_MultiMarginLoss_1d_no_reduce (__main__.TestNN)": [
    "RuntimeError: target out of range",
    [
      "linux"
    ]
  ],
  "test_MultiMarginLoss_1d_no_reduce_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_MultiMarginLoss_1d_sum_reduction_cuda_half (__main__.TestNN)": [
    "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
    [
      "linux"
    ]
  ],
  "test_MultiMarginLoss_cuda_half (__main__.TestNN)": [
    "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
    [
      "linux"
    ]
  ],
  "test_MultiMarginLoss_margin_cuda_half (__main__.TestNN)": [
    "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
    [
      "linux"
    ]
  ],
  "test_MultiMarginLoss_margin_no_reduce (__main__.TestNN)": [
    "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
    [
      "linux"
    ]
  ],
  "test_MultiMarginLoss_margin_no_reduce_cuda (__main__.TestNN)": [
    "RuntimeError: target out of range",
    [
      "linux"
    ]
  ],
  "test_MultiMarginLoss_margin_sum_reduction_cuda_half (__main__.TestNN)": [
    "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
    [
      "linux"
    ]
  ],
  "test_MultiMarginLoss_no_reduce (__main__.TestNN)": [
    "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
    [
      "linux"
    ]
  ],
  "test_MultiMarginLoss_no_reduce_cuda (__main__.TestNN)": [
    "RuntimeError: target out of range",
    [
      "linux"
    ]
  ],
  "test_MultiMarginLoss_p_cuda_half (__main__.TestNN)": [
    "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
    [
      "linux"
    ]
  ],
  "test_MultiMarginLoss_p_no_reduce (__main__.TestNN)": [
    "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
    [
      "linux"
    ]
  ],
  "test_MultiMarginLoss_p_no_reduce_cuda (__main__.TestNN)": [
    "RuntimeError: target out of range",
    [
      "linux"
    ]
  ],
  "test_MultiMarginLoss_p_sum_reduction_cuda_half (__main__.TestNN)": [
    "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
    [
      "linux"
    ]
  ],
  "test_MultiMarginLoss_sum_reduction_cuda_half (__main__.TestNN)": [
    "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
    [
      "linux"
    ]
  ],
  "test_MultiMarginLoss_weights_cuda_half (__main__.TestNN)": [
    "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
    [
      "linux"
    ]
  ],
  "test_MultiMarginLoss_weights_no_reduce (__main__.TestNN)": [
    "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
    [
      "linux"
    ]
  ],
  "test_MultiMarginLoss_weights_no_reduce_cuda (__main__.TestNN)": [
    "RuntimeError: target out of range",
    [
      "linux"
    ]
  ],
  "test_MultiMarginLoss_weights_sum_reduction_cuda_half (__main__.TestNN)": [
    "RuntimeError: \"multi_margin_loss_cpu_kernel\" not implemented for 'Half'",
    [
      "linux"
    ]
  ],
  "test_NLLLoss2d_no_reduce_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss2d_no_reduce_ignore_index_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss2d_no_reduce_weights_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLossNd_no_reduce_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLossNd_no_reduce_ignore_index_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLossNd_no_reduce_weights_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_2d_cuda_bfloat16 (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_2d_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-06:07:47.759.618 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_2d_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_2d_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_2d_ignore_index_cuda_bfloat16 (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_2d_ignore_index_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-06:07:47.775.331 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_2d_ignore_index_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_2d_ignore_index_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_2d_sum_reduction_cuda_bfloat16 (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_2d_sum_reduction_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-06:07:47.790.737 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_2d_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_2d_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_2d_weights_cuda_bfloat16 (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_2d_weights_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-06:07:47.848.302 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_2d_weights_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_2d_weights_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_cuda_bfloat16 (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:07:47.860.001 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_dim_is_3_cuda_bfloat16 (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_dim_is_3_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-06:07:47.873.922 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_dim_is_3_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_dim_is_3_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_dim_is_3_sum_reduction_cuda_bfloat16 (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_dim_is_3_sum_reduction_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-06:07:47.886.931 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_dim_is_3_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_dim_is_3_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_higher_dim_cuda_bfloat16 (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_higher_dim_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-06:07:47.906.933 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_higher_dim_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_higher_dim_cuda_half (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_higher_dim_sum_reduction_cuda_bfloat16 (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_higher_dim_sum_reduction_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss2d failed, detail:EZ1001: 2024-09-13-06:07:47.925.826 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_higher_dim_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_higher_dim_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_ignore_index_cuda_bfloat16 (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_ignore_index_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:07:48.047.984 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_ignore_index_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_ignore_index_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:07:48.061.808 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:07:48.074.392 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:07:48.086.611 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_no_reduce_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_no_reduce_ignore_index_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_no_reduce_weights_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_no_reduce_weights_ignore_index_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_no_reduce_weights_ignore_index_neg_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_sum_reduction_cuda_bfloat16 (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_sum_reduction_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:07:49.143.278 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_weights_cuda_bfloat16 (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_weights_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:07:49.343.965 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_weights_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_weights_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_weights_ignore_index_cuda_bfloat16 (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_weights_ignore_index_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:07:49.547.003 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_weights_ignore_index_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_weights_ignore_index_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_weights_ignore_index_neg_cuda_bfloat16 (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_weights_ignore_index_neg_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:07:49.747.094 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_weights_ignore_index_neg_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_NLLLoss_weights_ignore_index_neg_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_PReLU_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_PairwiseDistance_broadcast_lhs_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_PairwiseDistance_broadcast_rhs_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_PairwiseDistance_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_PairwiseDistance_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_PairwiseDistance_with_non_default_args_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_PixelShuffle_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_PixelUnshuffle_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_full_loss_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnInplaceMaskedFillScalar failed, detail:EZ1001: 2024-09-13-06:07:50.642.295 selfRef not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_INT32,DT_INT64,DT_FLOAT16,DT_INT8,DT_BOOL,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_full_loss_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_full_loss_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_full_loss_no_log_input_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnInplaceMaskedFillScalar failed, detail:EZ1001: 2024-09-13-06:07:53.242.308 selfRef not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_INT32,DT_INT64,DT_FLOAT16,DT_INT8,DT_BOOL,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_full_loss_no_log_input_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_full_loss_no_log_input_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_no_full_loss_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_no_full_loss_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_no_full_loss_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_no_full_loss_no_log_input_cuda_double (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_no_full_loss_no_log_input_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_no_full_loss_no_log_input_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_PoissonNLLLoss_no_reduce_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_RNN_change_dropout (__main__.TestNN)": [
    "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-06:07:56.583.068 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_RNN_cpu_vs_cudnn_no_dropout (__main__.TestNN)": [
    "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-06:07:56.599.054 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_RNN_cpu_vs_cudnn_with_dropout (__main__.TestNN)": [
    "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-06:07:56.612.584 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_RNN_cudnn_weight_norm (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_RNN_dropout (__main__.TestNN)": [
    "RuntimeError: call aclnnMatmul failed, detail:EZ1001: 2024-09-13-06:07:57.456.256 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_RNN_dropout_state (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_ReLU6_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_ReLU_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_ReplicationPad3d_complex (__main__.TestNN)": [
    "RuntimeError: npu_dtype_cast does not support automatic differentiation for outputs with complex dtype.",
    [
      "linux"
    ]
  ],
  "test_ReplicationPad3d_complex_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_ReplicationPad3d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_ReplicationPad3d_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_SELU_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_SiLU_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Sigmoid_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_beta (__main__.TestNN)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_beta_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-13-06:07:57.588.761 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-13-06:07:57.602.450 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-13-06:07:57.612.206 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-13-06:07:57.620.812 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_no_reduce (__main__.TestNN)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_no_reduce_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_no_reduce_scalar (__main__.TestNN)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_no_reduce_scalar_cuda (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_scalar_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-13-06:07:57.639.394 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_scalar_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_scalar_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_scalar_sum_reduction_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-13-06:07:57.652.026 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_scalar_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_scalar_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_sum_reduction_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-13-06:07:57.664.060 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_zero_beta (__main__.TestNN)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_SmoothL1Loss_zero_beta_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_SoftMarginLoss_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:57.678.870 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_SoftMarginLoss_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_SoftMarginLoss_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_SoftMarginLoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:57.690.089 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_SoftMarginLoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
    "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:57.695.175 target not implemented for DT_INT64, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_SoftMarginLoss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
    "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:57.699.935 target not implemented for DT_INT64, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_SoftMarginLoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:57.707.077 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_SoftMarginLoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
    "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:57.711.951 target not implemented for DT_INT64, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_SoftMarginLoss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
    "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:57.718.986 target not implemented for DT_INT64, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_SoftMarginLoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:57.726.377 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_SoftMarginLoss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
    "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:57.734.972 target not implemented for DT_INT64, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_SoftMarginLoss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
    "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:57.739.856 target not implemented for DT_INT64, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_SoftMarginLoss_no_reduce (__main__.TestNN)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_SoftMarginLoss_no_reduce_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_SoftMarginLoss_sum_reduction_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnSoftMarginLoss failed, detail:EZ1001: 2024-09-13-06:07:57.751.595 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_SoftMarginLoss_sum_reduction_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_SoftMarginLoss_sum_reduction_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_Softplus_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Softshrink_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Softsign_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Tanh_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Tanhshrink_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Threshold_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_TransformerDecoderLayer_gelu_activation_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_TransformerDecoderLayer_relu_activation (__main__.TestNN)": [
    "OverTimeError: Test exceeded time limit of 60 seconds.",
    [
      "linux"
    ]
  ],
  "test_TransformerDecoderLayer_relu_activation_cuda (__main__.TestNN)": [
    "OverTimeError: Test exceeded time limit of 60 seconds.",
    [
      "linux"
    ]
  ],
  "test_TransformerEncoderLayer_gelu_activation_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_TransformerEncoderLayer_relu_activation_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Transformer_multilayer_coder_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_TripletMarginLoss_no_batch_dim_mean_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNorm failed, detail:EZ1001: 2024-09-13-06:09:58.953.534 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_TripletMarginLoss_no_batch_dim_mean_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_TripletMarginLoss_no_batch_dim_mean_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_TripletMarginLoss_no_batch_dim_none_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNorm failed, detail:EZ1001: 2024-09-13-06:09:58.971.957 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_TripletMarginLoss_no_batch_dim_none_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_TripletMarginLoss_no_batch_dim_none_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_TripletMarginLoss_no_batch_dim_sum_cuda_double (__main__.TestNN)": [
    "RuntimeError: call aclnnNorm failed, detail:EZ1001: 2024-09-13-06:09:58.989.282 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_TripletMarginLoss_no_batch_dim_sum_cuda_float (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_TripletMarginLoss_no_batch_dim_sum_cuda_half (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_Unflatten_no_batch_dim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Unfold_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_Unfold_int_input_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_affine_grid (__main__.TestNN)": [
    "RuntimeError: call aclnnAffineGrid failed, detail:EZ1001: 2024-09-13-06:09:59.028.106 theta not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_batchnorm_cudnn_half (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_batchnorm_cudnn_nhwc (__main__.TestNN)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_batchnorm_nhwc_cpu (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_batchnorm_nhwc_cuda (__main__.TestNN)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_batchnorm_non_contig_cpu_SyncBatchNorm (__main__.TestNN)": [
    "ValueError: SyncBatchNorm expected input tensor to be on NPU or GPU",
    [
      "linux"
    ]
  ],
  "test_batchnorm_raises_error_if_running_var_or_running_mean_have_forward_grad (__main__.TestNN)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_bce_with_logits_has_correct_forward_grad (__main__.TestNN)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_cosine_embedding_loss_with_diff_type (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_cudnn_weight_format (__main__.TestNN)": [
    "AssertionError: Scalars are not equal!",
    [
      "linux"
    ]
  ],
  "test_cudnn_weight_tying (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_error_RNN_seq_len_zero (__main__.TestNN)": [
    "IndexError: select(): index -1 out of range for tensor of size [0, 10, 6] at dimension 0",
    [
      "linux"
    ]
  ],
  "test_grid_sample (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_grid_sample_3d (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_grid_sample_error_checking (__main__.TestNN)": [
    "AssertionError: \"Expected all tensors to be on the same device\" does not match \"only npu tensor is supported",
    [
      "linux"
    ]
  ],
  "test_grid_sample_nearest_neighbor_rounding_mode_consistency (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not equal!",
    [
      "linux"
    ]
  ],
  "test_interpolate (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_bicubic_2d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_bicubic_2d_zero_dim_cuda (__main__.TestNN)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_interpolate_bicubic_scale_2d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_bicubic_scale_tuple_shared_2d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_bicubic_scale_tuple_skewed_2d_align_corners_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_bicubic_scale_tuple_skewed_2d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_bicubic_tuple_2d_align_corners_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_bicubic_tuple_2d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_bilinear_2d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_bilinear_2d_zero_dim_cuda (__main__.TestNN)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_interpolate_bilinear_scale_2d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_bilinear_scale_tuple_shared_2d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_bilinear_scale_tuple_skewed_2d_align_corners_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_bilinear_scale_tuple_skewed_2d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_bilinear_tuple_2d_align_corners_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_bilinear_tuple_2d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_illegal_memory_access (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_linear_1d_align_corners_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_linear_1d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_linear_1d_zero_dim_cuda (__main__.TestNN)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_interpolate_linear_scale_1d_align_corners_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_linear_scale_1d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_linear_tuple_1d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_nearest_1d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_nearest_1d_zero_dim_cuda (__main__.TestNN)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_interpolate_nearest_2d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_nearest_2d_launch_configs_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_nearest_2d_zero_dim_cuda (__main__.TestNN)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_interpolate_nearest_3d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_nearest_3d_zero_dim_cuda (__main__.TestNN)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_interpolate_nearest_scale_1d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_nearest_scale_2d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_nearest_scale_3d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_nearest_tuple_1d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_nearest_tuple_2d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_nearest_tuple_3d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_trilinear_3d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_trilinear_3d_zero_dim_cuda (__main__.TestNN)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_interpolate_trilinear_scale_3d_align_corners_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_trilinear_scale_3d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_trilinear_tuple_3d_align_corners_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_interpolate_trilinear_tuple_3d_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_kl_div_log_softmax_target (__main__.TestNN)": [
    "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-06:10:08.198.044 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_kl_div_with_diff_type (__main__.TestNN)": [
    "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-06:10:08.202.451 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_kl_div_with_diff_type_log_target (__main__.TestNN)": [
    "RuntimeError: call aclnnKlDiv failed, detail:EZ1001: 2024-09-13-06:10:08.206.214 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_layer_norm_grads_with_create_graph_flag (__main__.TestNN)": [
    "RuntimeError: call aclnnLayerNorm failed, detail:EZ1001: 2024-09-13-06:10:17.205.689 input not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_linear_autograd_device_cuda_bias_weightCOO (__main__.TestNN)": [
    "RuntimeError: CAUTION: The operator 'aten::addmm' is not currently supported on the NPU backend.",
    [
      "linux"
    ]
  ],
  "test_linear_autograd_device_cuda_bias_weightCSC (__main__.TestNN)": [
    "RuntimeError: device type of values (npu) must be CPU or CUDA",
    [
      "linux"
    ]
  ],
  "test_linear_autograd_device_cuda_bias_weightCSR (__main__.TestNN)": [
    "RuntimeError: device type of values (npu) must be CPU or CUDA",
    [
      "linux"
    ]
  ],
  "test_linear_autograd_device_cuda_bias_weightStrided (__main__.TestNN)": [
    "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-06:10:17.268.757 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_linear_autograd_device_cuda_nobias_weightCOO (__main__.TestNN)": [
    "RuntimeError: CAUTION: The operator 'aten::addmm' is not currently supported on the NPU backend.",
    [
      "linux"
    ]
  ],
  "test_linear_autograd_device_cuda_nobias_weightCSC (__main__.TestNN)": [
    "RuntimeError: device type of values (npu) must be CPU or CUDA",
    [
      "linux"
    ]
  ],
  "test_linear_autograd_device_cuda_nobias_weightCSR (__main__.TestNN)": [
    "RuntimeError: device type of values (npu) must be CPU or CUDA",
    [
      "linux"
    ]
  ],
  "test_linear_autograd_device_cuda_nobias_weightStrided (__main__.TestNN)": [
    "RuntimeError: call aclnnMatmul failed, detail:EZ1001: 2024-09-13-06:10:17.317.022 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_load_state_dict_ref_cycle (__main__.TestNN)": [
    "AssertionError: Scalars are not equal!",
    [
      "linux"
    ]
  ],
  "test_log_softmax_dim0_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_log_softmax_dim3_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_log_softmax_lastdim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_log_softmax_scalar_cuda (__main__.TestNN)": [
    "RuntimeError: call aclnnLogSoftmaxBackward failed, detail:EZ1001: 2024-09-13-06:10:17.800.432 provided dim 0 not in the range of input size 0.",
    [
      "linux"
    ]
  ],
  "test_log_softmax_spatial_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_log_softmax_spatial_special_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_multimarginloss_1d_input_0d_target_no_reduce (__main__.TestNN)": [
    "RuntimeError: target out of range",
    [
      "linux"
    ]
  ],
  "test_multimarginloss_1d_input_0d_target_no_reduce_cuda (__main__.TestNN)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_partial_flat_weights (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_pdist (__main__.TestNN)": [
    "RuntimeError: call aclnnPdist failed, detail:EZ1001: 2024-09-13-06:10:18.492.699 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_pdist_empty_col (__main__.TestNN)": [
    "RuntimeError: call aclnnPdist failed, detail:EZ1001: 2024-09-13-06:10:18.513.270 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_pdist_empty_row (__main__.TestNN)": [
    "RuntimeError: call aclnnPdist failed, detail:EZ1001: 2024-09-13-06:10:18.519.295 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_pdist_large (__main__.TestNN)": [
    "RuntimeError: call aclnnPdist failed, detail:EZ1001: 2024-09-13-06:10:18.542.445 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_pdist_zeros (__main__.TestNN)": [
    "RuntimeError: call aclnnPdist failed, detail:EZ1001: 2024-09-13-06:10:18.551.524 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_smoothl1loss_intergral_target (__main__.TestNN)": [
    "RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-13-06:10:34.972.156 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_softmax_lastdim_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_softmax_spatial_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_softmax_spatial_special_cuda (__main__.TestNN)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_sync_batchnorm_accuracy_cuda (__main__.TestNN)": [
    "RuntimeError: NPU not support specify memory_format.",
    [
      "linux"
    ]
  ],
  "test_sync_batchnorm_backward_elemt (__main__.TestNN)": [
    "RuntimeError: call aclnnBatchNormElemtBackward failed, detail:EZ1001: 2024-09-13-06:10:35.057.677 gradOut not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_transformerdecoder (__main__.TestNN)": [
    "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-06:10:35.206.157 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_type (__main__.TestNN)": [
    "AssertionError: tensor([[-0., -0., -0., -0., 0., -0., 0., -0., -0., 0.],",
    [
      "linux"
    ]
  ],
  "test_upsampling_not_recompute_scale_factor (__main__.TestNN)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:10:44.969.651 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_fold_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bicubic_memory_format_torch_channels_last_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bicubic_memory_format_torch_contiguous_format_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bilinear_memory_format_torch_channels_last_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bilinear_memory_format_torch_contiguous_format_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bicubic_memory_format_torch_channels_last_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bicubic_memory_format_torch_contiguous_format_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bilinear_memory_format_torch_channels_last_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bilinear_memory_format_torch_contiguous_format_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bicubic_memory_format_torch_channels_last_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bicubic_memory_format_torch_contiguous_format_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bilinear_memory_format_torch_channels_last_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bilinear_memory_format_torch_contiguous_format_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bicubic_memory_format_torch_channels_last_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bicubic_memory_format_torch_contiguous_format_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bilinear_memory_format_torch_channels_last_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bilinear_memory_format_torch_contiguous_format_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest1d_mode_nearest-exact_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest1d_mode_nearest_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest2d_memory_format_torch_channels_last_mode_nearest-exact_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest2d_memory_format_torch_channels_last_mode_nearest_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest2d_memory_format_torch_contiguous_format_mode_nearest-exact_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest2d_memory_format_torch_contiguous_format_mode_nearest_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest3d_memory_format_torch_channels_last_3d_mode_nearest-exact_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest3d_memory_format_torch_channels_last_3d_mode_nearest_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest3d_memory_format_torch_contiguous_format_mode_nearest-exact_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest3d_memory_format_torch_contiguous_format_mode_nearest_cpu (__main__.TestNNDeviceTypeCPU)": [
    "AttributeError: 'function' object has no attribute 'graph'",
    [
      "linux"
    ]
  ],
  "test_BatchNorm_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_Bilinear_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_cudnn_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: only npu tensor is supported",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_empty_target_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: False is not true",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_no_batch_dim_reduction_mean_use_module_form_False_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: only npu tensor is supported",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_no_batch_dim_reduction_mean_use_module_form_True_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: only npu tensor is supported",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_no_batch_dim_reduction_none_use_module_form_False_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: only npu tensor is supported",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_no_batch_dim_reduction_none_use_module_form_True_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: only npu tensor is supported",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_no_batch_dim_reduction_sum_use_module_form_False_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: only npu tensor is supported",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_no_batch_dim_reduction_sum_use_module_form_True_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: only npu tensor is supported",
    [
      "linux"
    ]
  ],
  "test_GRU_grad_and_gradgrad_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-13-06:12:46.268.809 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_GroupNorm_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnGroupNorm failed, detail:EZ1001: 2024-09-13-06:12:46.274.056 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_BFLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_GroupNorm_general_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnGroupNorm failed, detail:EZ1001: 2024-09-13-06:12:46.283.272 Expected eps to be greater than 0, got 0.000000.",
    [
      "linux"
    ]
  ],
  "test_GroupNorm_memory_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: NPU not support specify memory_format.",
    [
      "linux"
    ]
  ],
  "test_GroupNorm_numeric_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_InstanceNorm1d_general_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_InstanceNorm2d_general_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_InstanceNorm3d_general_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_LSTM_grad_and_gradgrad_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-13-06:12:46.312.943 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_LayerNorm_general_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_LayerNorm_numeric_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_LocalResponseNorm_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_MarginLoss_empty_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_MarginLoss_empty_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_MarginLoss_warnings_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-06:12:46.369.970 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_ReflectionPad2d_large_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_ReflectionPad3d_large_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_ReflectionPad_empty_cuda_complex64 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-13-06:12:47.011.479 self not implemented for DT_COMPLEX64, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_ReflectionPad_empty_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_ReplicationPad1d_large_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_ReplicationPad2d_large_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_ReplicationPad3d_large_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "TypeError: isinstance() arg 2 must be a type or tuple of types",
    [
      "linux"
    ]
  ],
  "test_ReplicationPad_empty_cuda_complex128 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-13-06:12:47.373.921 self not implemented for DT_COMPLEX128, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_ReplicationPad_empty_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_TransformerDecoderLayer_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-06:12:47.411.004 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_TransformerDecoder_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-06:12:47.449.639 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_TransformerEncoderLayer_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-06:12:47.475.650 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_TransformerEncoder_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-06:12:47.505.840 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_Transformer_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-06:12:48.035.883 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_Unfold_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnIm2col failed, detail:EZ1001: 2024-09-13-06:12:48.044.601 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_activations_bfloat16_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_affine_2d_rotate0_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_affine_2d_rotate45_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_affine_2d_rotate90_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_affine_2d_rotateRandom_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_affine_3d_rotateRandom_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_batchnorm_affine_cuda_bfloat16 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_batchnorm_affine_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_batchnorm_affine_mixed_cuda_bfloat16 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_batchnorm_affine_mixed_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_batchnorm_eval_cuda_bfloat16 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_batchnorm_eval_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_batchnorm_eval_mixed_cuda_bfloat16 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_batchnorm_eval_mixed_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_batchnorm_grad_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnBatchNorm failed, detail:EZ1001: 2024-09-13-06:12:48.101.064 input not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_batchnorm_simple_average_cuda_bfloat16 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_batchnorm_simple_average_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_batchnorm_simple_average_mixed_cuda_bfloat16 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_batchnorm_simple_average_mixed_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_batchnorm_update_stats_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Scalars are not equal!",
    [
      "linux"
    ]
  ],
  "test_channel_shuffle_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not equal!",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_error_if_nonfinite_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-13-06:12:48.122.308 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_foreach_False_norm_type_0_5_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_foreach_False_norm_type_1_5_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_foreach_False_norm_type_2_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-13-06:12:48.153.235 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_foreach_False_norm_type_4_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_foreach_False_norm_type_inf_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_foreach_True_norm_type_0_5_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_foreach_True_norm_type_1_5_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_foreach_True_norm_type_2_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-13-06:12:48.167.395 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_foreach_True_norm_type_4_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_foreach_True_norm_type_inf_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_clip_grad_value_foreach_False_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: tensor(0., device='npu:0') not less than or equal to 2.5",
    [
      "linux"
    ]
  ],
  "test_clip_grad_value_foreach_True_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: tensor(0., device='npu:0') not less than or equal to 2.5",
    [
      "linux"
    ]
  ],
  "test_conv_empty_input_cuda_complex128 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnAdd failed, detail:EZ1001: 2024-09-13-06:12:48.182.079 other not implemented for DT_COMPLEX128, should be in dtype support list [DT_FLOAT,DT_INT32,DT_INT64,DT_FLOAT16,DT_INT16,DT_INT8,DT_UINT8,DT_DOUBLE,DT_BOOL,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_conv_empty_input_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: NPU not support specify memory_format.",
    [
      "linux"
    ]
  ],
  "test_conv_empty_input_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: NPU not support specify memory_format.",
    [
      "linux"
    ]
  ],
  "test_conv_empty_input_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: NPU not support specify memory_format.",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_label_smoothing_consistent_index_target_and_probs_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:12:48.202.367 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_label_smoothing_weight_ignore_indices_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:12:48.223.135 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_label_smoothing_with_probs_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_large_tensor_reduction_mean_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "TypeError: isinstance() arg 2 must be a type or tuple of types",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_large_tensor_reduction_none_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "TypeError: isinstance() arg 2 must be a type or tuple of types",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_large_tensor_reduction_sum_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "TypeError: isinstance() arg 2 must be a type or tuple of types",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_loss_index_target_unit_weights_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:12:48.754.675 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_loss_one_hot_target_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:12:48.768.713 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_loss_prob_target_all_reductions_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_mean_weighted_False_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_mean_weighted_True_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_none_weighted_False_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_none_weighted_True_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_sum_weighted_False_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_sum_weighted_True_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_loss_prob_target_unit_weights_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_ctc_loss_cudnn_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: only npu tensor is supported",
    [
      "linux"
    ]
  ],
  "test_device_mask_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: shape '[5, 5]' is invalid for input of size 12",
    [
      "linux"
    ]
  ],
  "test_elu_inplace_overlap_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: RuntimeError not raised",
    [
      "linux"
    ]
  ],
  "test_elu_inplace_with_neg_alpha_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: \"call out-of-place version\" does not match \"call aclnnEluBackward failed, detail:EZ1001: 2024-09-13-06:12:48.811.163 gradOutput not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_fold_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnIm2colBackward failed, detail:EZ1001: 2024-09-13-06:12:48.820.315 gradOutput not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_grid_sample_half_precision_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_grid_sample_large_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_grid_sample_large_index_2d_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
    "TypeError: isinstance() arg 2 must be a type or tuple of types",
    [
      "linux"
    ]
  ],
  "test_grid_sample_large_index_2d_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
    "TypeError: isinstance() arg 2 must be a type or tuple of types",
    [
      "linux"
    ]
  ],
  "test_grid_sample_large_index_3d_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
    "TypeError: isinstance() arg 2 must be a type or tuple of types",
    [
      "linux"
    ]
  ],
  "test_grid_sample_large_index_3d_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
    "TypeError: isinstance() arg 2 must be a type or tuple of types",
    [
      "linux"
    ]
  ],
  "test_grid_sample_nan_inf_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_grid_sample_nan_inf_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_gumbel_softmax_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: tensor(0., device='npu:0', dtype=torch.float16) not greater than or equal to 0",
    [
      "linux"
    ]
  ],
  "test_gumbel_softmax_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: tensor(0., device='npu:0', dtype=torch.float32) not greater than or equal to 0",
    [
      "linux"
    ]
  ],
  "test_gumbel_softmax_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: tensor(0., device='npu:0', dtype=torch.float32) not greater than or equal to 0",
    [
      "linux"
    ]
  ],
  "test_hardsigmoid_grad_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnHardsigmoid failed, detail:EZ1001: 2024-09-13-06:12:49.517.293 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT32,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_hardswish_grad_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnHardswish failed, detail:EZ1001: 2024-09-13-06:12:49.523.007 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_hardswish_inplace_overlap_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: \"unsupported operation\" does not match \"call aclnnInplaceHardswish failed, detail:EZ1001: 2024-09-13-06:12:49.527.979 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_instancenorm_raises_error_for_single_spatial_element_during_training_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnBatchNorm failed, detail:EZ1001: 2024-09-13-06:12:49.533.170 input not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_invalid_reduction_strings_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-13-06:12:49.550.060 self not implemented for DT_COMPLEX64, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_layernorm_half_precision_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not equal!",
    [
      "linux"
    ]
  ],
  "test_layernorm_weight_bias_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_leaky_relu_inplace_overlap_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: RuntimeError not raised",
    [
      "linux"
    ]
  ],
  "test_leaky_relu_inplace_with_neg_slope_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: \"call out-of-place version\" does not match \"call aclnnLeakyReluBackward failed, detail:EZ1001: 2024-09-13-06:12:49.561.292 In-place leakyRelu backward calculation is triggered with a negativeSlope which is not supported.",
    [
      "linux"
    ]
  ],
  "test_leaky_relu_inplace_with_zero_slope_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_linear_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-06:12:49.578.345 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_log_softmax_big_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_log_softmax_big_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_logsigmoid_out_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-13-06:12:49.593.483 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_lstmcell_backward_only_one_output_grad_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: True is not false",
    [
      "linux"
    ]
  ],
  "test_masked_softmax_TxT_layout_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_masked_softmax_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnNanToNum failed, detail:EZ1001: 2024-09-13-06:12:49.807.314 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_BFLOAT16,DT_INT8,DT_INT16,DT_INT32,DT_INT64,DT_UINT8,DT_BOOL,].",
    [
      "linux"
    ]
  ],
  "test_masked_softmax_devices_parity_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnInplaceMaskedFillScalar failed, detail:EZ1001: 2024-09-13-06:12:49.813.360 selfRef not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_INT32,DT_INT64,DT_FLOAT16,DT_INT8,DT_BOOL,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_masked_softmax_forward_with_nans_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnInplaceMaskedFillScalar failed, detail:EZ1001: 2024-09-13-06:12:49.820.690 selfRef not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_INT32,DT_INT64,DT_FLOAT16,DT_INT8,DT_BOOL,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_masked_softmax_grad_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnInplaceMaskedFillScalar failed, detail:EZ1001: 2024-09-13-06:12:49.827.702 selfRef not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_INT32,DT_INT64,DT_FLOAT16,DT_INT8,DT_BOOL,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_masked_softmax_mask_types_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnNanToNum failed, detail:EZ1001: 2024-09-13-06:12:49.834.957 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_BFLOAT16,DT_INT8,DT_INT16,DT_INT32,DT_INT64,DT_UINT8,DT_BOOL,].",
    [
      "linux"
    ]
  ],
  "test_masked_softmax_transformer_layout_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_mish_inplace_overlap_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: \"unsupported operation\" does not match \"call aclnnInplaceMish failed, detail:EZ1001: 2024-09-13-06:12:50.228.076 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_module_to_empty_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnMatmul failed, detail:EZ1001: 2024-09-13-06:12:50.234.896 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nll_loss_all_ignored_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:12:50.240.991 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nll_loss_byte_target_matches_long_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:12:50.249.369 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nll_loss_empty_tensor_reduction_mean_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:12:50.258.224 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nll_loss_empty_tensor_reduction_none_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:12:50.265.977 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nll_loss_empty_tensor_reduction_sum_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:12:50.274.114 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nll_loss_invalid_target_dim_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: \"1D target tensor expected\" does not match \"call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:12:50.282.776 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nll_loss_invalid_weights_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: \"weight tensor should be defined either for all 3 classes or no classes\" does not match \"call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:12:50.291.062 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nll_loss_large_tensor_reduction_mean_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "TypeError: isinstance() arg 2 must be a type or tuple of types",
    [
      "linux"
    ]
  ],
  "test_nll_loss_large_tensor_reduction_none_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "TypeError: isinstance() arg 2 must be a type or tuple of types",
    [
      "linux"
    ]
  ],
  "test_nll_loss_large_tensor_reduction_sum_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "TypeError: isinstance() arg 2 must be a type or tuple of types",
    [
      "linux"
    ]
  ],
  "test_nll_loss_out_of_bounds_ignore_index_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:12:50.904.013 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nll_loss_total_weight_is_zero_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:12:50.915.485 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nn_empty_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-13-06:12:50.924.755 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nn_scalars_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnEluBackward failed, detail:EZ1001: 2024-09-13-06:12:50.930.524 gradOutput not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nn_scalars_reductions_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-13-06:12:50.939.824 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nonlinearity_propagate_nan_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnRelu failed, detail:EZ1001: 2024-09-13-06:12:50.945.634 Self dtype DT_DOUBLE should be in dtype support list [[DT_FLOAT,DT_FLOAT16,DT_INT8,DT_UINT8,DT_INT32,DT_INT64,]DT_BF16].",
    [
      "linux"
    ]
  ],
  "test_one_hot_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: The values for attribute 'shape' do not match: torch.Size([4, 1]) != torch.Size([4, 5]).",
    [
      "linux"
    ]
  ],
  "test_overwrite_module_params_on_conversion_cpu_device_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: False is not true",
    [
      "linux"
    ]
  ],
  "test_pad_cuda_complex128 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-13-06:12:50.955.912 self not implemented for DT_COMPLEX128, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_pad_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: \"Padding size should be less than the corresponding input dimension\" does not match \"call aclnnReflectionPad2d failed, detail:EZ1001: 2024-09-13-06:12:50.977.985 padding size should be less than the corresponding self dimention.",
    [
      "linux"
    ]
  ],
  "test_prelu_backward_32bit_indexing_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "TypeError: isinstance() arg 2 must be a type or tuple of types",
    [
      "linux"
    ]
  ],
  "test_rnn_fused_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_rnn_fused_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_rnn_retain_variables_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_rnn_retain_variables_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_rnn_retain_variables_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_smooth_l1_loss_vs_huber_loss_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-13-06:12:51.252.142 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_smoothl1loss_backward_zero_beta_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-06:12:51.258.538 promoteType dtype DT_DOUBLE should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_softmax_64bit_indexing_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
    "TypeError: isinstance() arg 2 must be a type or tuple of types",
    [
      "linux"
    ]
  ],
  "test_softmax_backward_64bit_indexing_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "TypeError: isinstance() arg 2 must be a type or tuple of types",
    [
      "linux"
    ]
  ],
  "test_softmax_bfloat16_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_softmax_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not equal!",
    [
      "linux"
    ]
  ],
  "test_softmax_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not equal!",
    [
      "linux"
    ]
  ],
  "test_softmax_results_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_softmax_results_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_softplus_low_threshold_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnSoftplus failed, detail:EZ1001: 2024-09-13-06:12:51.641.863 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_softshrink_negative_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: \"lambda must be greater or equal to 0, but found to be -1\\.\" does not match \"lambd should be greater than 0",
    [
      "linux"
    ]
  ],
  "test_threshold_inplace_overlap_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnInplaceThreshold failed, detail:EZ1001: 2024-09-13-06:12:51.655.817 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_INT32,DT_FLOAT16,DT_INT8,DT_UINT8,DT_INT16,DT_INT64,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_transformerencoderlayer_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_transformerencoderlayer_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_transformerencoderlayer_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-06:12:51.671.753 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_transformerencoderlayer_gelu_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_transformerencoderlayer_gelu_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_triplet_margin_with_distance_loss_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnNorm failed, detail:EZ1001: 2024-09-13-06:12:51.684.897 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_triplet_margin_with_distance_loss_default_parity_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnNorm failed, detail:EZ1001: 2024-09-13-06:12:51.691.841 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bicubic_memory_format_torch_channels_last_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bicubic_memory_format_torch_contiguous_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:12:51.705.362 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bilinear_memory_format_torch_channels_last_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bilinear_memory_format_torch_contiguous_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: upsample_binlinear_2d not support torch.fp64 dtypes",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bicubic_memory_format_torch_channels_last_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bicubic_memory_format_torch_contiguous_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:12:51.724.887 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bilinear_memory_format_torch_channels_last_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bilinear_memory_format_torch_contiguous_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: upsample_binlinear_2d not support torch.fp64 dtypes",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bicubic_memory_format_torch_channels_last_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bicubic_memory_format_torch_contiguous_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bilinear_memory_format_torch_channels_last_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bilinear_memory_format_torch_contiguous_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bicubic_memory_format_torch_channels_last_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bicubic_memory_format_torch_contiguous_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bilinear_memory_format_torch_channels_last_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bilinear_memory_format_torch_contiguous_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_3_mode_bicubic_float64_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:12:52.066.381 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_3_mode_bilinear_float64_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: upsample_binlinear_2d not support torch.fp64 dtypes",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_5_mode_bicubic_float64_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:12:52.234.521 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_5_mode_bilinear_float64_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: upsample_binlinear_2d not support torch.fp64 dtypes",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_True_num_channels_3_mode_bicubic_uint8_cuda_uint8 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: RuntimeError not raised",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_True_num_channels_3_mode_bilinear_uint8_cuda_uint8 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: RuntimeError not raised",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_True_num_channels_5_mode_bicubic_uint8_cuda_uint8 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: RuntimeError not raised",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_True_num_channels_5_mode_bilinear_uint8_cuda_uint8 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: RuntimeError not raised",
    [
      "linux"
    ]
  ],
  "test_upsamplingBicubic2d_aa_correctness_memory_format_torch_channels_last_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBicubic2d_aa_correctness_memory_format_torch_contiguous_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBicubic2d_correctness_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:12:52.628.604 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBilinear2d_aa_correctness_memory_format_torch_channels_last_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBilinear2d_aa_correctness_memory_format_torch_contiguous_format_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest1d_correctness_isize_10_osize_15_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest1d_correctness_isize_20_osize_11_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest1d_mode_nearest-exact_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest1d_mode_nearest_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest2d_correctness_memory_format_torch_channels_last_isize_10_osize_15_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest2d_correctness_memory_format_torch_channels_last_isize_20_osize_11_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest2d_correctness_memory_format_torch_contiguous_format_isize_10_osize_15_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest2d_correctness_memory_format_torch_contiguous_format_isize_20_osize_11_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest2d_memory_format_torch_channels_last_mode_nearest-exact_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest2d_memory_format_torch_channels_last_mode_nearest_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest2d_memory_format_torch_contiguous_format_mode_nearest-exact_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest2d_memory_format_torch_contiguous_format_mode_nearest_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest3d_correctness_memory_format_torch_channels_last_3d_isize_10_osize_15_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest3d_correctness_memory_format_torch_channels_last_3d_isize_20_osize_11_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest3d_correctness_memory_format_torch_contiguous_format_isize_10_osize_15_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest3d_correctness_memory_format_torch_contiguous_format_isize_20_osize_11_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest3d_memory_format_torch_channels_last_3d_mode_nearest-exact_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest3d_memory_format_torch_channels_last_3d_mode_nearest_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest3d_memory_format_torch_contiguous_format_mode_nearest-exact_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest3d_memory_format_torch_contiguous_format_mode_nearest_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: call aclnnUpsampleNearest3d failed, detail:EZ1001: 2024-09-13-06:13:05.807.677 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_DOUBLE,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact1d_correctness_isize_10_osize_15_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact1d_correctness_isize_20_osize_11_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact1d_rescale_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact2d_correctness_memory_format_torch_channels_last_isize_10_osize_15_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact2d_correctness_memory_format_torch_channels_last_isize_20_osize_11_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact2d_correctness_memory_format_torch_contiguous_format_isize_10_osize_15_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact2d_correctness_memory_format_torch_contiguous_format_isize_20_osize_11_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact3d_correctness_memory_format_torch_channels_last_3d_isize_10_osize_15_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact3d_correctness_memory_format_torch_channels_last_3d_isize_20_osize_11_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact3d_correctness_memory_format_torch_contiguous_format_isize_10_osize_15_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact3d_correctness_memory_format_torch_contiguous_format_isize_20_osize_11_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingTrilinear3d_align_corners_False_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_upsamplingTrilinear3d_align_corners_True_cuda (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_upsampling_64bit_indexing_channels_last_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
    "TypeError: isinstance() arg 2 must be a type or tuple of types",
    [
      "linux"
    ]
  ],
  "test_variable_sequence_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_variable_sequence_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_variable_sequence_cuda_float64 (__main__.TestNNDeviceTypeCUDA)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_warp_softmax_64bit_indexing_cuda_float16 (__main__.TestNNDeviceTypeCUDA)": [
    "TypeError: isinstance() arg 2 must be a type or tuple of types",
    [
      "linux"
    ]
  ],
  "test_warp_softmax_64bit_indexing_cuda_float32 (__main__.TestNNDeviceTypeCUDA)": [
    "TypeError: isinstance() arg 2 must be a type or tuple of types",
    [
      "linux"
    ]
  ],
  "test_BatchNorm_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_Bilinear_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_empty_target_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: False is not true",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_no_batch_dim_reduction_mean_use_module_form_False_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnCtcLoss failed, detail:EZ1001: 2024-09-13-06:13:06.912.419 DimNum of logProbs [2] must equal 3.",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_no_batch_dim_reduction_mean_use_module_form_True_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnCtcLoss failed, detail:EZ1001: 2024-09-13-06:13:06.919.819 DimNum of logProbs [2] must equal 3.",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_no_batch_dim_reduction_none_use_module_form_False_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnCtcLoss failed, detail:EZ1001: 2024-09-13-06:13:06.945.261 DimNum of logProbs [2] must equal 3.",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_no_batch_dim_reduction_none_use_module_form_True_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnCtcLoss failed, detail:EZ1001: 2024-09-13-06:13:06.952.810 DimNum of logProbs [2] must equal 3.",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_no_batch_dim_reduction_sum_use_module_form_False_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnCtcLoss failed, detail:EZ1001: 2024-09-13-06:13:06.959.846 DimNum of logProbs [2] must equal 3.",
    [
      "linux"
    ]
  ],
  "test_CTCLoss_no_batch_dim_reduction_sum_use_module_form_True_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnCtcLoss failed, detail:EZ1001: 2024-09-13-06:13:06.966.816 DimNum of logProbs [2] must equal 3.",
    [
      "linux"
    ]
  ],
  "test_GRU_grad_and_gradgrad_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-13-06:13:06.974.746 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_GroupNorm_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnGroupNorm failed, detail:EZ1001: 2024-09-13-06:13:06.979.915 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_BFLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_GroupNorm_general_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnGroupNorm failed, detail:EZ1001: 2024-09-13-06:13:06.988.881 Expected eps to be greater than 0, got 0.000000.",
    [
      "linux"
    ]
  ],
  "test_GroupNorm_memory_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU not support specify memory_format.",
    [
      "linux"
    ]
  ],
  "test_GroupNorm_numeric_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_InstanceNorm1d_general_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_InstanceNorm2d_general_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_InstanceNorm3d_general_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_LSTM_grad_and_gradgrad_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-13-06:13:07.008.779 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_LayerNorm_general_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_LayerNorm_numeric_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_LocalResponseNorm_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_MarginLoss_empty_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_MarginLoss_empty_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_ReflectionPad_empty_npu_complex64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-13-06:13:07.062.468 self not implemented for DT_COMPLEX64, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_ReflectionPad_empty_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_ReplicationPad1d_large_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_ReplicationPad2d_large_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_ReplicationPad_empty_npu_complex128 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-13-06:13:07.115.312 self not implemented for DT_COMPLEX128, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_ReplicationPad_empty_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_TransformerDecoderLayer_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-06:13:07.152.277 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_TransformerDecoder_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-06:13:07.189.605 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_TransformerEncoderLayer_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-06:13:07.216.703 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_TransformerEncoder_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-06:13:07.247.724 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_Transformer_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-06:13:07.761.039 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_Unfold_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnIm2col failed, detail:EZ1001: 2024-09-13-06:13:07.769.178 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_affine_2d_rotate0_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_affine_2d_rotate45_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_affine_2d_rotate90_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_affine_2d_rotateRandom_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_affine_3d_rotateRandom_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_batchnorm_affine_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_batchnorm_eval_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_batchnorm_grad_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnBatchNorm failed, detail:EZ1001: 2024-09-13-06:13:07.789.139 input not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_batchnorm_simple_average_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_batchnorm_update_stats_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Scalars are not equal!",
    [
      "linux"
    ]
  ],
  "test_channel_shuffle_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not equal!",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_error_if_nonfinite_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-13-06:13:07.803.215 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_foreach_False_norm_type_0_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_foreach_False_norm_type_1_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_foreach_False_norm_type_2_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-13-06:13:07.814.195 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_foreach_False_norm_type_4_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_foreach_False_norm_type_inf_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_foreach_True_norm_type_0_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_foreach_True_norm_type_1_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_foreach_True_norm_type_2_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-13-06:13:07.827.763 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_foreach_True_norm_type_4_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_clip_grad_norm_foreach_True_norm_type_inf_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_clip_grad_value_foreach_False_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: tensor(0., device='npu:0') not less than or equal to 2.5",
    [
      "linux"
    ]
  ],
  "test_clip_grad_value_foreach_True_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: tensor(0., device='npu:0') not less than or equal to 2.5",
    [
      "linux"
    ]
  ],
  "test_conv_empty_input_npu_bfloat16 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU not support specify memory_format.",
    [
      "linux"
    ]
  ],
  "test_conv_empty_input_npu_complex128 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnAdd failed, detail:EZ1001: 2024-09-13-06:13:07.846.840 other not implemented for DT_COMPLEX128, should be in dtype support list [DT_FLOAT,DT_INT32,DT_INT64,DT_FLOAT16,DT_INT16,DT_INT8,DT_UINT8,DT_DOUBLE,DT_BOOL,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_conv_empty_input_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU not support specify memory_format.",
    [
      "linux"
    ]
  ],
  "test_conv_empty_input_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU not support specify memory_format.",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_label_smoothing_consistent_index_target_and_probs_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:13:07.862.300 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_label_smoothing_weight_ignore_indices_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:13:07.881.928 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_label_smoothing_with_probs_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_loss_index_target_unit_weights_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:13:07.903.030 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_loss_one_hot_target_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:13:07.916.820 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_loss_prob_target_all_reductions_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_mean_weighted_False_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_mean_weighted_True_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_none_weighted_False_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_none_weighted_True_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_sum_weighted_False_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_loss_prob_target_no_batch_dim_reduction_sum_weighted_True_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Scalars are not close!",
    [
      "linux"
    ]
  ],
  "test_cross_entropy_loss_prob_target_unit_weights_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_ctc_loss_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnLinalgVectorNorm failed, detail:EZ1001: 2024-09-13-06:13:07.955.036 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_elu_inplace_overlap_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: RuntimeError not raised",
    [
      "linux"
    ]
  ],
  "test_elu_inplace_with_neg_alpha_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: \"call out-of-place version\" does not match \"call aclnnEluBackward failed, detail:EZ1001: 2024-09-13-06:13:07.961.701 gradOutput not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_fold_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnIm2colBackward failed, detail:EZ1001: 2024-09-13-06:13:07.970.651 gradOutput not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_grid_sample_nan_inf_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_grid_sample_nan_inf_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_gumbel_softmax_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: tensor(0., device='npu:0', dtype=torch.float32) not greater than or equal to 0",
    [
      "linux"
    ]
  ],
  "test_gumbel_softmax_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: tensor(0., device='npu:0', dtype=torch.float32) not greater than or equal to 0",
    [
      "linux"
    ]
  ],
  "test_hardsigmoid_grad_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnHardsigmoid failed, detail:EZ1001: 2024-09-13-06:13:07.990.242 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT32,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_hardswish_grad_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnHardswish failed, detail:EZ1001: 2024-09-13-06:13:07.995.251 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_hardswish_inplace_overlap_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: \"unsupported operation\" does not match \"call aclnnInplaceHardswish failed, detail:EZ1001: 2024-09-13-06:13:08.000.108 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_instancenorm_raises_error_for_single_spatial_element_during_training_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnBatchNorm failed, detail:EZ1001: 2024-09-13-06:13:08.004.939 input not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_invalid_reduction_strings_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-13-06:13:08.021.041 self not implemented for DT_COMPLEX64, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_leaky_relu_inplace_overlap_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: RuntimeError not raised",
    [
      "linux"
    ]
  ],
  "test_leaky_relu_inplace_with_neg_slope_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: \"call out-of-place version\" does not match \"call aclnnLeakyReluBackward failed, detail:EZ1001: 2024-09-13-06:13:08.029.570 In-place leakyRelu backward calculation is triggered with a negativeSlope which is not supported.",
    [
      "linux"
    ]
  ],
  "test_leaky_relu_inplace_with_zero_slope_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_linear_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnAddmm failed, detail:EZ1001: 2024-09-13-06:13:08.045.874 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_log_softmax_big_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_logsigmoid_out_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-13-06:13:08.054.125 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_mish_inplace_overlap_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: \"unsupported operation\" does not match \"call aclnnInplaceMish failed, detail:EZ1001: 2024-09-13-06:13:40.825.142 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_module_to_empty_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnMatmul failed, detail:EZ1001: 2024-09-13-06:13:40.836.671 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nll_loss_all_ignored_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:13:40.842.333 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nll_loss_byte_target_matches_long_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:13:40.851.280 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nll_loss_empty_tensor_reduction_mean_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:13:40.859.507 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nll_loss_empty_tensor_reduction_none_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:13:40.867.524 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nll_loss_empty_tensor_reduction_sum_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:13:40.875.117 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nll_loss_invalid_target_dim_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: \"1D target tensor expected\" does not match \"call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:13:40.883.036 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nll_loss_invalid_weights_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: \"weight tensor should be defined either for all 3 classes or no classes\" does not match \"call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:13:40.891.221 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nll_loss_out_of_bounds_ignore_index_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:13:40.903.870 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nll_loss_total_weight_is_zero_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnNLLLoss failed, detail:EZ1001: 2024-09-13-06:13:40.911.777 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nn_empty_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnLogSigmoidForward failed, detail:EZ1001: 2024-09-13-06:13:40.919.931 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nn_scalars_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnEluBackward failed, detail:EZ1001: 2024-09-13-06:13:40.925.808 gradOutput not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nn_scalars_reductions_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnBinaryCrossEntropy failed, detail:EZ1001: 2024-09-13-06:13:40.935.184 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_nonlinearity_propagate_nan_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnRelu failed, detail:EZ1001: 2024-09-13-06:13:40.940.234 Self dtype DT_DOUBLE should be in dtype support list [[DT_FLOAT,DT_FLOAT16,DT_INT8,DT_UINT8,DT_INT32,DT_INT64,]DT_BF16].",
    [
      "linux"
    ]
  ],
  "test_one_hot_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: RuntimeError not raised",
    [
      "linux"
    ]
  ],
  "test_pad_npu_complex128 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnInplaceNormal failed, detail:EZ1001: 2024-09-13-06:13:40.964.348 self not implemented for DT_COMPLEX128, should be in dtype support list [DT_FLOAT16,DT_FLOAT,DT_DOUBLE,DT_INT16,DT_INT32,DT_INT64,DT_INT8,DT_UINT8,DT_BOOL,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_pad_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: \"Padding size should be less than the corresponding input dimension\" does not match \"call aclnnReflectionPad2d failed, detail:EZ1001: 2024-09-13-06:13:40.985.729 padding size should be less than the corresponding self dimention.",
    [
      "linux"
    ]
  ],
  "test_rnn_retain_variables_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_smooth_l1_loss_vs_huber_loss_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnSmoothL1Loss failed, detail:EZ1001: 2024-09-13-06:13:41.045.554 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_smoothl1loss_backward_zero_beta_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnL1Loss failed, detail:EZ1001: 2024-09-13-06:13:41.050.930 promoteType dtype DT_DOUBLE should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_INT64,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_softmax_bfloat16_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_softmax_results_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_softplus_low_threshold_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnSoftplus failed, detail:EZ1001: 2024-09-13-06:13:41.069.805 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_softshrink_negative_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: \"lambda must be greater or equal to 0, but found to be -1\\.\" does not match \"lambd should be greater than 0",
    [
      "linux"
    ]
  ],
  "test_threshold_inplace_overlap_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnInplaceThreshold failed, detail:EZ1001: 2024-09-13-06:13:41.083.649 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_INT32,DT_FLOAT16,DT_INT8,DT_UINT8,DT_INT16,DT_INT64,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_transformerencoderlayer_gelu_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_transformerencoderlayer_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_triplet_margin_with_distance_loss_default_parity_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnNorm failed, detail:EZ1001: 2024-09-13-06:13:41.097.664 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_triplet_margin_with_distance_loss_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnNorm failed, detail:EZ1001: 2024-09-13-06:13:41.106.618 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_BFLOAT16,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_channels_last_align_corners_False_input_size_399_output_size_437_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_channels_last_align_corners_False_input_size_403_output_size_377_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_channels_last_align_corners_True_input_size_399_output_size_437_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_channels_last_align_corners_True_input_size_403_output_size_377_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_contiguous_format_align_corners_False_input_size_399_output_size_437_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:41.124.033 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_contiguous_format_align_corners_False_input_size_403_output_size_377_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:41.132.046 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_contiguous_format_align_corners_True_input_size_399_output_size_437_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:41.139.681 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiLinear2d_consistency_interp_size_bug_memory_format_torch_contiguous_format_align_corners_True_input_size_403_output_size_377_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:41.147.672 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bicubic_memory_format_torch_channels_last_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bicubic_memory_format_torch_contiguous_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:41.157.641 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bilinear_memory_format_torch_channels_last_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_False_mode_bilinear_memory_format_torch_contiguous_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: upsample_binlinear_2d not support torch.fp64 dtypes",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bicubic_memory_format_torch_channels_last_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bicubic_memory_format_torch_contiguous_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:41.177.352 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bilinear_memory_format_torch_channels_last_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_False_align_corners_True_mode_bilinear_memory_format_torch_contiguous_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: upsample_binlinear_2d not support torch.fp64 dtypes",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bicubic_memory_format_torch_channels_last_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bicubic_memory_format_torch_contiguous_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bilinear_memory_format_torch_channels_last_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_False_mode_bilinear_memory_format_torch_contiguous_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bicubic_memory_format_torch_channels_last_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bicubic_memory_format_torch_contiguous_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bilinear_memory_format_torch_channels_last_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_antialias_True_align_corners_True_mode_bilinear_memory_format_torch_contiguous_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_channels_last_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.252.220 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.260.786 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.268.956 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.276.691 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.294.582 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.302.985 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.310.781 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.318.457 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.326.011 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.334.035 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.341.325 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.349.189 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.357.159 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.364.746 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.372.722 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.380.307 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.388.181 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.396.173 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.403.549 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.411.326 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.418.709 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.426.174 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.433.818 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.441.307 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.449.023 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.456.733 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.464.420 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.472.575 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.480.146 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.488.243 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.495.895 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.503.475 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.511.547 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.519.763 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.527.771 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.535.835 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.543.737 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.551.920 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.559.826 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.567.925 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.575.856 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.583.920 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.591.868 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.599.735 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.607.527 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.615.587 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.623.417 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.632.300 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.640.330 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.648.322 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.656.327 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.664.090 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.671.229 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.678.885 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.686.163 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.693.635 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.701.327 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.708.860 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.716.460 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.723.870 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.731.445 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.739.005 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.746.723 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.754.688 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.762.030 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.769.702 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.777.077 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.784.419 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.792.234 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.799.684 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.807.090 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.814.804 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.822.100 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.829.311 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.838.601 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.846.274 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.853.917 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.861.285 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.868.998 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.876.506 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.883.743 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.891.524 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.898.770 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.906.259 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.913.367 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.920.638 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.928.158 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.935.698 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.943.139 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.951.211 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.958.647 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.966.556 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.974.471 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.982.381 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.990.043 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:42.997.649 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bicubic_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: ",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.662.698 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.670.570 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.678.075 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.685.414 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.693.102 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.701.263 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.709.347 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.717.436 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.725.450 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.733.553 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.741.544 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.749.472 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.757.224 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.765.794 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.773.540 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.781.366 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.789.192 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.797.438 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.805.373 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.813.385 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.821.269 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.829.294 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.836.983 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.847.393 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.855.676 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.863.955 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.871.488 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.878.939 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.886.156 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.893.730 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.901.382 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.908.788 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.916.529 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.924.477 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.932.127 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.939.886 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.947.507 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.955.368 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.963.071 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.970.724 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.978.341 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.985.809 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:44.992.823 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.000.230 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.007.806 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.015.299 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.023.258 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.030.860 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.038.366 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.046.064 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.053.771 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.061.417 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.069.203 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.077.169 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.084.747 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.092.065 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.099.420 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.106.488 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.114.148 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.121.937 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.129.150 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.136.988 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.144.755 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.152.400 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.160.101 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.167.923 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.175.364 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.182.871 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.190.376 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.197.686 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.204.709 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.212.204 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.220.075 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.228.013 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.235.451 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.243.143 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.250.236 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.258.143 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.265.896 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.273.211 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.280.574 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.287.809 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.295.127 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.302.480 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.309.858 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.317.601 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.325.395 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.333.135 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.340.779 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.348.963 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.356.622 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.364.103 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.371.544 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.379.149 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.386.527 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_False_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBilinear2d failed, detail:EZ1001: 2024-09-13-06:13:45.394.380 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_False_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_3_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_32_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_False_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_False_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_restrided_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_1_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_consistency_memory_format_torch_contiguous_format_mode_bilinear_antialias_True_align_corners_True_num_channels_5_output_size_600_check_as_unsqueezed_3d_tensor_True_non_contig_sliced_batch_size_5_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_3_mode_bicubic_float64_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:46.707.879 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_3_mode_bilinear_float64_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: upsample_binlinear_2d not support torch.fp64 dtypes",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_5_mode_bicubic_float64_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:46.894.234 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_False_num_channels_5_mode_bilinear_float64_npu_float64 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: upsample_binlinear_2d not support torch.fp64 dtypes",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_True_num_channels_3_mode_bicubic_uint8_npu_uint8 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: RuntimeError not raised",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_True_num_channels_3_mode_bilinear_uint8_npu_uint8 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: RuntimeError not raised",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_True_num_channels_5_mode_bicubic_uint8_npu_uint8 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: RuntimeError not raised",
    [
      "linux"
    ]
  ],
  "test_upsamplingBiMode2d_nonsupported_dtypes_antialias_True_num_channels_5_mode_bilinear_uint8_npu_uint8 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: RuntimeError not raised",
    [
      "linux"
    ]
  ],
  "test_upsamplingBicubic2d_aa_correctness_memory_format_torch_channels_last_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBicubic2d_aa_correctness_memory_format_torch_contiguous_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingBicubic2d_correctness_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleBicubic2d failed, detail:EZ1001: 2024-09-13-06:13:47.360.019 self not implemented for DT_DOUBLE, should be in dtype support list [DT_FLOAT16,DT_FLOAT,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingBilinear2d_aa_correctness_memory_format_torch_channels_last_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingBilinear2d_aa_correctness_memory_format_torch_contiguous_format_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest1d_correctness_isize_10_osize_15_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest1d_correctness_isize_20_osize_11_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest1d_mode_nearest-exact_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest1d_mode_nearest_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest2d_correctness_memory_format_torch_channels_last_isize_10_osize_15_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest2d_correctness_memory_format_torch_channels_last_isize_20_osize_11_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest2d_correctness_memory_format_torch_contiguous_format_isize_10_osize_15_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest2d_correctness_memory_format_torch_contiguous_format_isize_20_osize_11_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest2d_memory_format_torch_channels_last_mode_nearest-exact_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest2d_memory_format_torch_channels_last_mode_nearest_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest2d_memory_format_torch_contiguous_format_mode_nearest-exact_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest2d_memory_format_torch_contiguous_format_mode_nearest_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest3d_correctness_memory_format_torch_channels_last_3d_isize_10_osize_15_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest3d_correctness_memory_format_torch_channels_last_3d_isize_20_osize_11_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest3d_correctness_memory_format_torch_contiguous_format_isize_10_osize_15_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest3d_correctness_memory_format_torch_contiguous_format_isize_20_osize_11_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest3d_memory_format_torch_channels_last_3d_mode_nearest-exact_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest3d_memory_format_torch_channels_last_3d_mode_nearest_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: NPU contiguous operator only supportted contiguous memory format.",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest3d_memory_format_torch_contiguous_format_mode_nearest-exact_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearest3d_memory_format_torch_contiguous_format_mode_nearest_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: call aclnnUpsampleNearest3d failed, detail:EZ1001: 2024-09-13-06:13:47.582.314 self not implemented for DT_UINT8, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_DOUBLE,].",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact1d_correctness_isize_10_osize_15_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact1d_correctness_isize_20_osize_11_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact1d_rescale_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact2d_correctness_memory_format_torch_channels_last_isize_10_osize_15_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact2d_correctness_memory_format_torch_channels_last_isize_20_osize_11_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact2d_correctness_memory_format_torch_contiguous_format_isize_10_osize_15_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact2d_correctness_memory_format_torch_contiguous_format_isize_20_osize_11_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact3d_correctness_memory_format_torch_channels_last_3d_isize_10_osize_15_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact3d_correctness_memory_format_torch_channels_last_3d_isize_20_osize_11_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact3d_correctness_memory_format_torch_contiguous_format_isize_10_osize_15_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingNearestExact3d_correctness_memory_format_torch_contiguous_format_isize_20_osize_11_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ],
  "test_upsamplingTrilinear3d_align_corners_False_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_upsamplingTrilinear3d_align_corners_True_npu (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "RuntimeError: Comparing",
    [
      "linux"
    ]
  ],
  "test_variable_sequence_npu_float32 (__main__.TestNNDeviceTypePRIVATEUSE1)": [
    "AssertionError: Tensor-likes are not close!",
    [
      "linux"
    ]
  ]
}